{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwuBjSFTaO1-"
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIACFx-xESDu"
      },
      "source": [
        "# Here we're inporting the MNIST dataset under the Keras API. The Keras Python library makes creating deep learning model a quick process\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d43pr_6VbHEG"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEphXxmAtPf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "06624b84-9773-443a-a17b-2aebb38d1b76"
      },
      "source": [
        "# We're going to display an image below with Matplotlib.\n",
        " \n",
        "image_index = 45786 # You may select any number up to 60,000 here\n",
        "print(y_train[image_index]) # This line will tell us what label the image has. This is import as we need to check how accurate our models are!\n",
        "plt.imshow(x_train[image_index], cmap='Greys') # Here we can choose how we want to import the image. Right now, it is set to import in greyscale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faaba2356a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANuElEQVR4nO3df6hc9ZnH8c/HbEMwEYmbS4iJbrpVQVnYVAazRAkJav2BoAExFSxZlE2FRCv0jw3xj4ogJLJtMbBUkjUklZgQ04gRda2rRa1/lIyS1ajsqiGxuUZzRSERka65z/5xT8qN3jlzM+fMD33eLxhm5jxz5jw55HPPzPnOzNcRIQDffWf0uwEAvUHYgSQIO5AEYQeSIOxAEn/Ty43NmjUr5s+f38tNAqkcPHhQn3zyiSeqVQq77WslPSRpiqT/iIh1ZY+fP3++ms1mlU0CKNFoNFrWOn4Zb3uKpH+XdJ2kSyTdavuSTp8PQHdVec9+maT3IuJARPxF0g5JN9bTFoC6VQn7XEl/Hnf/cLHsFLZX2m7abo6MjFTYHIAqun42PiI2RkQjIhpDQ0Pd3hyAFqqEfVjSeePuzyuWARhAVcK+V9KFtr9ve6qkH0vaU09bAOrW8dBbRHxle7Wk5zQ29LY5It6qrTMAtao0zh4Rz0h6pqZeAHQRH5cFkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiUqzuKIe27dvL63fddddpfXPPvusznZOMTo6Wlp/6aWXSuuLFy+usx1UUCnstg9KOi7phKSvIqJRR1MA6lfHkX1pRHxSw/MA6CLeswNJVA17SPq97ddsr5zoAbZX2m7abo6MjFTcHIBOVQ37FRFxqaTrJK2y/Y2zMRGxMSIaEdEYGhqquDkAnaoU9ogYLq6PSnpC0mV1NAWgfh2H3fZ022edvC3pR5L219UYgHpVORs/W9ITtk8+z2MR8Z+1dPUd8/DDD5fWV61aVVov9nHH9SrOOKP8eHDDDTeU1nfv3t2ydtVVV3XUEzrTcdgj4oCkf6yxFwBdxNAbkARhB5Ig7EAShB1IgrADSfAV1xp8+eWXpfWdO3d2dftnn312y9qiRYtK192/v/yjER988EFp/YsvviitP/TQQy1rDL31Fkd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYaTJs2rbR+zTXXlNbb/Rzz+eefX1rftGlTy9qVV15Zuu769etL62vXri2t49uDIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4ew3afZ/9ueeeK60vW7astP7YY4+V1qdOndqyVrU3fHdwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn74F2UzZfdNFFlZ7/+PHjLWuPPvpo6brtvks/OjpaWm83pfOGDRtK6+idtkd225ttH7W9f9yyc2w/b/vd4npmd9sEUNVkXsZvkXTt15atkfRCRFwo6YXiPoAB1jbsEfGypE+/tvhGSVuL21sl3VRzXwBq1ukJutkRcaS4/ZGk2a0eaHul7abt5sjISIebA1BV5bPxERGSoqS+MSIaEdEYGhqqujkAHeo07B/bniNJxfXR+loC0A2dhn2PpBXF7RWSnqynHQDd0nac3fZ2SUskzbJ9WNIvJK2TtNP2HZIOSbqlm00Ouna/G191HP3YsWOl9ccff7xl7e677y5d13Zpvd04+uLFi0vrvHUbHG3DHhG3tiiVzz4AYKDwcVkgCcIOJEHYgSQIO5AEYQeS4CuuA+DAgQOl9TvvvLO0/uKLL9bZzml55ZVXSutXX311y9q9995buu6SJUtK6zNmzCit41Qc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZe6DdOHjZWLTU/muog2zv3r0tazfdVP7Thdu2bSutL1++vKOesuLIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7eA2VjzWht165dpXXG2U8PR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9h6IiNL66Ohoab3dtMmrVq1qWVuzZk3puueee25pvZ3h4eHS+qJFi1rWDh8+XLru7t27S+vr1q0rrbf7t2fT9shue7Pto7b3j1t2n+1h2/uKy/XdbRNAVZN5Gb9F0rUTLP91RCwoLs/U2xaAurUNe0S8LOnTHvQCoIuqnKBbbfuN4mX+zFYPsr3SdtN2c2RkpMLmAFTRadh/I+kHkhZIOiLpl60eGBEbI6IREY2hoaEONwegqo7CHhEfR8SJiBiVtEnSZfW2BaBuHYXd9pxxd5dJ2t/qsQAGQ9txdtvbJS2RNMv2YUm/kLTE9gJJIemgpJ92scdvvYULF5bWjx07Vun5zzzzzJa1KVOmVHrudubOnVtaf+qpp1rWLr300krbXr9+fWl99erVLWsZ53ZvG/aIuHWCxY90oRcAXcTHZYEkCDuQBGEHkiDsQBKEHUiCr7j2wNKlS/vdQt90c4ir3ZBlu68WZ8ORHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuB34wfA9u3bS+sXX3xxaX3BggV1tnNann322dL6Pffc07JW9XfdH3jggdL6WWedVen5v2vaHtltn2f7D7bftv2W7Z8Vy8+x/bztd4vrmd1vF0CnJvMy/itJP4+ISyT9k6RVti+RtEbSCxFxoaQXivsABlTbsEfEkYh4vbh9XNI7kuZKulHS1uJhWyXd1K0mAVR3WifobM+X9ENJf5I0OyKOFKWPJM1usc5K203bzZGRkQqtAqhi0mG3PUPS7yTdExGnzKgXY2daJjzbEhEbI6IREY2hoaFKzQLo3KTCbvt7Ggv6tojYXSz+2Pacoj5H0tHutAigDm2H3mxb0iOS3omIX40r7ZG0QtK64vrJrnSYwG233VZanz59emm9yiumFStWlNa3bNlSWh8eHi6tnzhxomVt7L9W5xYuXFhp/WwmM85+uaSfSHrT9r5i2VqNhXyn7TskHZJ0S3daBFCHtmGPiD9KavUn+Mp62wHQLXxcFkiCsANJEHYgCcIOJEHYgST4iusAuOCCC0rr77//fmn90KFDHW/7/vvvL623+xpqlbHyadOmldaXLl1aqY5TcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZx8Ar776aml9x44dpfUHH3ywZe3DDz/sqKe6lI2lb9iwoXTd22+/ve52UuPIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJuOq0uaej0WhEs9ns2fay+Pzzz1vWnn766dJ1d+3aVVq/+eabO+rppHnz5rWsXX755ZWeG9/UaDTUbDYn/JEBjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMRk5mc/T9JvJc2WFJI2RsRDtu+T9C+SRoqHro2IZ7rVKFqbMWNGy9ry5ctL121Xx3fHZH684itJP4+I122fJek1288XtV9HxL91rz0AdZnM/OxHJB0pbh+3/Y6kud1uDEC9Tus9u+35kn4o6U/FotW237C92fbMFuustN203RwZGZnoIQB6YNJhtz1D0u8k3RMRxyT9RtIPJC3Q2JH/lxOtFxEbI6IREY2hoaEaWgbQiUmF3fb3NBb0bRGxW5Ii4uOIOBERo5I2Sbqse20CqKpt2D02Tecjkt6JiF+NWz5n3MOWSdpff3sA6jKZs/GXS/qJpDdt7yuWrZV0q+0FGhuOOyjpp13pEEAtJnM2/o+SJvp+LGPqwLcIn6ADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dMpm22PSDo0btEsSZ/0rIHTM6i9DWpfEr11qs7e/i4iJvz9t56G/Rsbt5sR0ehbAyUGtbdB7Uuit071qjdexgNJEHYgiX6HfWOft19mUHsb1L4keutUT3rr63t2AL3T7yM7gB4h7EASfQm77Wtt/4/t92yv6UcPrdg+aPtN2/tsN/vcy2bbR23vH7fsHNvP2363uJ5wjr0+9Xaf7eFi3+2zfX2fejvP9h9sv237Lds/K5b3dd+V9NWT/dbz9+y2p0j6X0lXSzosaa+kWyPi7Z420oLtg5IaEdH3D2DYXizpc0m/jYh/KJY9KOnTiFhX/KGcGRH/OiC93Sfp835P413MVjRn/DTjkm6S9M/q474r6esW9WC/9ePIfpmk9yLiQET8RdIOSTf2oY+BFxEvS/r0a4tvlLS1uL1VY/9Zeq5FbwMhIo5ExOvF7eOSTk4z3td9V9JXT/Qj7HMl/Xnc/cMarPneQ9Lvbb9me2W/m5nA7Ig4Utz+SNLsfjYzgbbTePfS16YZH5h918n051Vxgu6broiISyVdJ2lV8XJ1IMXYe7BBGjud1DTevTLBNON/1c991+n051X1I+zDks4bd39esWwgRMRwcX1U0hMavKmoPz45g25xfbTP/fzVIE3jPdE04xqAfdfP6c/7Efa9ki60/X3bUyX9WNKePvTxDbanFydOZHu6pB9p8Kai3iNpRXF7haQn+9jLKQZlGu9W04yrz/uu79OfR0TPL5Ku19gZ+fcl3duPHlr09feS/ru4vNXv3iRt19jLuv/T2LmNOyT9raQXJL0r6b8knTNAvT0q6U1Jb2gsWHP61NsVGnuJ/oakfcXl+n7vu5K+erLf+LgskAQn6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgif8HTjIfWnR6ugMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-o6eWThAyU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16f210b7-9e96-4689-a029-cb693bbc90d0"
      },
      "source": [
        "# We're going to check how many examples are in our dataset. The first number will tell us how many images are in the training dataset. The second and third number tell us the sizes of those images.\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYKpTkcKA4M8"
      },
      "source": [
        "# Reshaping the array to 4 dimensions so that it can work with the Keras API\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItbVQez1KDZr"
      },
      "source": [
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPYgNw2Xecsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1ee11910-ee64-4a16-a2af-ec5d8a31a341"
      },
      "source": [
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "Number of images in x_train 60000\n",
            "Number of images in x_test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1N909IxA9hQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a4e1370-e2bf-496b-ac8f-c771f5091f50"
      },
      "source": [
        "# Importing the required Keras modules containing model and layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAQYOO9cLD5i"
      },
      "source": [
        "# Creating a Sequential Model and adding the layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation=tf.nn.softmax))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP4aQFODhvT8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvEFOFWeBCka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea869e0a-1883-4849-9b40-ec8e66659d71"
      },
      "source": [
        "# Below we are using the \"Adam\" optimizer. This updates network weights iteratively based on training data.\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy']) # We can print the accuracy and loss with these lines of code\n",
        "model.fit(x=x_train,y=y_train, epochs=50) # An epoch is generally defined as \"one pass over the entire dataset\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 34s 569us/step - loss: 0.2076 - accuracy: 0.9384\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 34s 567us/step - loss: 0.0874 - accuracy: 0.9732\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 34s 569us/step - loss: 0.0620 - accuracy: 0.9806\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 34s 568us/step - loss: 0.0453 - accuracy: 0.9855\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 34s 568us/step - loss: 0.0369 - accuracy: 0.9877\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 34s 566us/step - loss: 0.0309 - accuracy: 0.9897\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 34s 561us/step - loss: 0.0265 - accuracy: 0.9907\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 34s 567us/step - loss: 0.0228 - accuracy: 0.9921\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 34s 566us/step - loss: 0.0220 - accuracy: 0.9926\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 34s 562us/step - loss: 0.0192 - accuracy: 0.9931\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 34s 563us/step - loss: 0.0168 - accuracy: 0.9944\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 34s 567us/step - loss: 0.0178 - accuracy: 0.9942\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 34s 564us/step - loss: 0.0140 - accuracy: 0.9953\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 34s 561us/step - loss: 0.0152 - accuracy: 0.9946\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 34s 566us/step - loss: 0.0133 - accuracy: 0.9957\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 34s 566us/step - loss: 0.0131 - accuracy: 0.9957\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 34s 571us/step - loss: 0.0125 - accuracy: 0.9957\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 34s 562us/step - loss: 0.0143 - accuracy: 0.9953\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 34s 561us/step - loss: 0.0125 - accuracy: 0.9957\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 33s 557us/step - loss: 0.0117 - accuracy: 0.9962\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 34s 563us/step - loss: 0.0113 - accuracy: 0.9959\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 34s 561us/step - loss: 0.0124 - accuracy: 0.9962\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 33s 558us/step - loss: 0.0107 - accuracy: 0.9967\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 34s 561us/step - loss: 0.0101 - accuracy: 0.9963\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 33s 554us/step - loss: 0.0102 - accuracy: 0.9967\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 34s 559us/step - loss: 0.0107 - accuracy: 0.9967\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 34s 563us/step - loss: 0.0094 - accuracy: 0.9968\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 33s 553us/step - loss: 0.0108 - accuracy: 0.9964\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 33s 556us/step - loss: 0.0102 - accuracy: 0.9969\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 33s 553us/step - loss: 0.0115 - accuracy: 0.9966\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 33s 556us/step - loss: 0.0082 - accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 34s 560us/step - loss: 0.0104 - accuracy: 0.9969\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 34s 560us/step - loss: 0.0090 - accuracy: 0.9973\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 34s 564us/step - loss: 0.0103 - accuracy: 0.9969\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 34s 572us/step - loss: 0.0080 - accuracy: 0.9973\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 34s 566us/step - loss: 0.0086 - accuracy: 0.9973\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 33s 557us/step - loss: 0.0083 - accuracy: 0.9971\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 33s 555us/step - loss: 0.0087 - accuracy: 0.9973\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 33s 554us/step - loss: 0.0091 - accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 33s 556us/step - loss: 0.0089 - accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 33s 557us/step - loss: 0.0093 - accuracy: 0.9970\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 33s 550us/step - loss: 0.0074 - accuracy: 0.9979\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 33s 548us/step - loss: 0.0094 - accuracy: 0.9973\n",
            "Epoch 44/50\n",
            "49760/60000 [=======================>......] - ETA: 5s - loss: 0.0066 - accuracy: 0.9977"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTAXqHlBbVB"
      },
      "source": [
        "# If we want to see our prediction results and confidence score, we can go ahead and run this line of code\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjpdrBOIkf9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmwiu2EFCl0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0afd9eb7-d781-416f-d0d5-35d920722165"
      },
      "source": [
        "from random import randint\n",
        "\n",
        "image_index = (randint(0, 10000)) # Choose any number less than 60,000 here so we can test our model!\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys') # Just like a previous line we write above. Displays the image on a graph in greyscale\n",
        "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1)) # Here we'll display the prediction with our image\n",
        "print(pred.argmax())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}